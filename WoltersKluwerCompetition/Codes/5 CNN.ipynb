{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohg4RpC0ftya",
        "outputId": "1f3f88fb-a6e4-4d25-8dac-a11d95a26338"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import nltk\n",
        "import keras  # only for loading the dataset and preprocessing\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from gensim.models import word2vec, KeyedVectors\n",
        "from sklearn.model_selection import train_test_split\n",
        "import gensim.downloader\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "import time\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqTARRtTgNIA",
        "outputId": "1ac318e3-71a9-4410-ad0e-0ba5eed5b151"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['answer_w2vCNN.csv',\n",
              " 'output',\n",
              " '.ipynb_checkpoints',\n",
              " 'regulationword2vec_mincount1.model',\n",
              " 'regulationword2vec_mincount1-300.model',\n",
              " 'answer_w2vCNNv2.csv',\n",
              " 'answer_w2vCNNv3.csv',\n",
              " 'answer_w2vCNNv4.csv',\n",
              " 'answer_w2vCNNv5.csv',\n",
              " 'answer_w2vCNNv6.csv',\n",
              " 'answer_w2vCNNv7.csv',\n",
              " 'answer_w2vCNNv8.csv',\n",
              " 'answer_w2vCNNv9.csv',\n",
              " 'pretrained_data_for_CNN_LSTM.csv',\n",
              " 'pretrained_test_data_for_CNN_LSTM.csv',\n",
              " 'answer_w2vCNNv10.csv',\n",
              " 'answer_w2vCNNv11.csv',\n",
              " 'answer_w2vCNNv12.csv',\n",
              " 'answer_w2vLSTMv1.csv',\n",
              " 'answer_w2vCNNv13.csv',\n",
              " 'answer_w2vCNNv14.csv',\n",
              " 'answer_w2vCNNv15.csv',\n",
              " 'answer_w2vCNNv17.csv',\n",
              " 'answer_w2vCNNv18.csv',\n",
              " 'answer_w2vCNNv19.csv',\n",
              " 'answer_w2vCNNv20.csv',\n",
              " 'answer_w2vCNNv21.csv',\n",
              " 'answer_w2vCNNv22.csv',\n",
              " 'answer_w2vCNNv23.csv',\n",
              " 'answer_w2vCNNv24.csv',\n",
              " 'selftrain_w2v+CNN_LSTM.ipynb']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# connect to google drive\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "path = \"/content/drive/MyDrive/DataSolve/competition/Word2Vec+CNN\"\n",
        "\n",
        "os.chdir(path)\n",
        "os.listdir(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rfbd1H4BgcGM"
      },
      "outputs": [],
      "source": [
        "# import train and test data\n",
        "df = pd.read_csv('../data/train_final.csv')\n",
        "df.drop('Unnamed: 0', axis =1, inplace = True)\n",
        "df['context'] = df['name'] + '. ' + df['document_text']\n",
        "\n",
        "test_df = pd.read_csv('../data/test.csv')\n",
        "test_df['context'] = test_df['name'] + '. ' + test_df['document_text']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['context'].head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kxy8GZWBWQWS",
        "outputId": "259c3cb3-1d42-4ee4-f95f-c14b9f30780c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    Consent Order in the Matter of Solium Financia...\n",
              "1    Alberta Securities Commission Warns Investors ...\n",
              "2    Exempt Market Dealer Agrees to Settlement. The...\n",
              "3    Canadian Securities Regulators Announces Consu...\n",
              "4    CSA Consultation Paper 51-405 Consideration of...\n",
              "Name: context, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YPPvKpp5gkNh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbf4c514-b2ba-487f-e054-5a14f6f036ab"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Accounting and Finance',\n",
              " 'Antitrust',\n",
              " 'Banking',\n",
              " 'Broker Dealer',\n",
              " 'Commodities Trading',\n",
              " 'Compliance Management',\n",
              " 'Consumer protection',\n",
              " 'Contract Provisions',\n",
              " 'Corporate Communications',\n",
              " 'Corporate Governance',\n",
              " 'Definitions',\n",
              " 'Delivery',\n",
              " 'Examinations',\n",
              " 'Exemptions',\n",
              " 'Fees and Charges',\n",
              " 'Financial Accounting',\n",
              " 'Financial Crime',\n",
              " 'Forms',\n",
              " 'Fraud',\n",
              " 'IT Risk',\n",
              " 'Information Filing',\n",
              " 'Insurance',\n",
              " 'Legal',\n",
              " 'Legal Proceedings',\n",
              " 'Licensing',\n",
              " 'Licensure and certification',\n",
              " 'Liquidity Risk',\n",
              " 'Listing',\n",
              " 'Market Abuse',\n",
              " 'Market Risk',\n",
              " 'Monetary and Economic Policy',\n",
              " 'Money Services',\n",
              " 'Money-Laundering and Terrorist Financing',\n",
              " 'Natural Disasters',\n",
              " 'Payments and Settlements',\n",
              " 'Powers and Duties',\n",
              " 'Quotation',\n",
              " 'Records Maintenance',\n",
              " 'Regulatory Actions',\n",
              " 'Regulatory Reporting',\n",
              " 'Required Disclosures',\n",
              " 'Research',\n",
              " 'Risk Management',\n",
              " 'Securities Clearing',\n",
              " 'Securities Issuing',\n",
              " 'Securities Management',\n",
              " 'Securities Sales',\n",
              " 'Securities Settlement',\n",
              " 'Trade Pricing',\n",
              " 'Trade Settlement']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# generate target columns\n",
        "label_cols = [col for col in df.columns if col not in ['id', 'name', 'document_text', 'context']]\n",
        "label_cols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i4qKq-WEg2F4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "outputId": "4c7cc328-3654-4d66-8822-01c128a7f8d0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([2959., 1195.,  456.,  215.,   80.,   49.,   22.,   11.,    3.,\n",
              "           3.]),\n",
              " array([  59. ,  181.6,  304.2,  426.8,  549.4,  672. ,  794.6,  917.2,\n",
              "        1039.8, 1162.4, 1285. ]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# find out the distribution of context lengths\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "def bag_of_words(text):\n",
        "    # TODO: Implement bag of words\n",
        "    return len(text.split(' '))\n",
        "plt.hist(test_df['context'].apply(bag_of_words))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7QYXcx1CkdzK"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    if text == None:\n",
        "        return None\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"what's\", \"what is \", text)\n",
        "    text = re.sub(r\"\\'s\", \" \", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
        "    text = re.sub(r\"can't\", \"can not \", text)\n",
        "    text = re.sub(r\"n't\", \" not \", text)\n",
        "    text = re.sub(r\"i'm\", \"i am \", text)\n",
        "    text = re.sub(r\"\\'re\", \" are \", text)\n",
        "    text = re.sub(r\"\\'d\", \" would \", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
        "    text = re.sub(r\"\\'scuse\", \" excuse \", text)\n",
        "    text = re.sub('\\W', ' ', text)\n",
        "    text = re.sub('\\s+', ' ', text)\n",
        "    text = re.sub('\\d+', ' ', text)\n",
        "    text = re.sub('_+', ' ', text)\n",
        "    text = re.sub(' +', ' ', text)\n",
        "    text = text.strip(' ')\n",
        "    \n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N29dObst-x9o"
      },
      "outputs": [],
      "source": [
        "def tokenizer(text):\n",
        "    sentences = nltk.sent_tokenize(text)\n",
        "\n",
        "    sentences = [nltk.word_tokenize(sentence) for sentence in sentences]\n",
        "\n",
        "    for i in range(len(sentences)):\n",
        "        sentences[i] = [word for word in sentences[i] if word not in stopwords.words('english')]\n",
        "    \n",
        "    return sentences[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['context'] = df['context'].map(lambda con: tokenizer(clean_text(con)))\n",
        "test_df['context'] = test_df['context'].map(lambda con: tokenizer(clean_text(con)))"
      ],
      "metadata": {
        "id": "j40lhQeez4k5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_list = []\n",
        "for i in df['context']:\n",
        "    word_list += i\n",
        "\n",
        "for i in test_df['context']:\n",
        "    word_list += i"
      ],
      "metadata": {
        "id": "mvTknZlA1nek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_list = pd.Series(word_list).unique()"
      ],
      "metadata": {
        "id": "ojXnoFcS2Eim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(word_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFBVHIw72X-a",
        "outputId": "39258483-9a47-4be5-b0c5-5157f3ff4f7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "34473"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_list.sort()"
      ],
      "metadata": {
        "id": "bnmUFPzKxbD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = 1 \n",
        "word_dict = {}\n",
        "for word in word_list:\n",
        "    \n",
        "    word_dict.update({word: index})\n",
        "    index += 1"
      ],
      "metadata": {
        "id": "4jGXM6Bh2PNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_dict"
      ],
      "metadata": {
        "id": "osXwualz2epU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_word2vec = word2vec.Word2Vec.load('regulationword2vec_mincount1-300.model')"
      ],
      "metadata": {
        "id": "BfvypyxWGEiC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['pretrained'] = df['context'].map(lambda li: pd.Series(li).map(lambda word: my_word2vec.wv.index2word.index(word)))"
      ],
      "metadata": {
        "id": "ooihA1eJ4EEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df['pretrained'] = test_df['context'].map(lambda li: pd.Series(li).map(lambda word: my_word2vec.wv.index2word.index(word)))"
      ],
      "metadata": {
        "id": "kXhWhPYL4sgG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('pretrained_data_for_CNN_LSTM.csv', index=False)"
      ],
      "metadata": {
        "id": "5o0Lv_OE6k2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.to_csv('pretrained_test_data_for_CNN_LSTM.csv', index=False)"
      ],
      "metadata": {
        "id": "3h8ZdGYK7cnw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uvSCnG0MJKHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import train and test data\n",
        "df = pd.read_csv('pretrained_data_for_CNN_LSTM.csv')\n",
        "\n",
        "\n",
        "test_df = pd.read_csv('pretrained_test_data_for_CNN_LSTM.csv')"
      ],
      "metadata": {
        "id": "DtRJFmRtJvnN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[''].head()"
      ],
      "metadata": {
        "id": "qRDpIUlkJvhn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cec4e23-2c44-4fe5-ccdb-8facdd744c0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    ['consent', 'order', 'matter', 'solium', 'fina...\n",
              "1    ['alberta', 'securities', 'commission', 'warns...\n",
              "2    ['exempt', 'market', 'dealer', 'agrees', 'sett...\n",
              "3    ['canadian', 'securities', 'regulators', 'anno...\n",
              "4    ['csa', 'consultation', 'paper', 'consideratio...\n",
              "Name: context, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gb_12tR_HToL"
      },
      "outputs": [],
      "source": [
        "def w2vpreprocess(sentence_list):\n",
        "    words_list = []\n",
        "    for sentence in sentence_list:   \n",
        "        temp = clean_text(sentence)\n",
        "        if temp != '':\n",
        "            words = tokenizer(temp)\n",
        "            words_list.append(words)\n",
        "\n",
        "    return words_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tTEtCmw9Kvlg"
      },
      "outputs": [],
      "source": [
        "df['w2v_list'] = df['sentence'].map(lambda x: w2vpreprocess(x))\n",
        "test_df['w2v_list'] = test_df['sentence'].map(lambda x: w2vpreprocess(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_EITOMiH_jsZ"
      },
      "outputs": [],
      "source": [
        "sentences = df['w2v_list'].values.tolist() + test_df['w2v_list'].values.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences"
      ],
      "metadata": {
        "id": "jkY_ghbRBoUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZkHn_FEt0Ng"
      },
      "outputs": [],
      "source": [
        "ns = []\n",
        "for item in sentences:\n",
        "    for i in item:\n",
        "        ns.append(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F76M1W1UHJwV",
        "outputId": "b2015049-7531-4e6f-ec73-c351e02edc47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken : 26.32 mins\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "my_word2vec = word2vec.Word2Vec(sentences=ns,\n",
        "                 sg=1, \n",
        "                 size=300,\n",
        "                 window=5,\n",
        "                 negative=5,\n",
        "                 min_count=1,\n",
        "                 iter=100 \n",
        "              )\n",
        "\n",
        "print(f'Time taken : {(time.time() - start_time) / 60:.2f} mins')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QMOGb6-2MGDB"
      },
      "outputs": [],
      "source": [
        "my_word2vec.save('regulationword2vec_mincount1-300.model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sz4tPlLxEswt"
      },
      "outputs": [],
      "source": [
        "my_word2vec.wv.vocab"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_word2vec.wv.index2word"
      ],
      "metadata": {
        "id": "Rv2QTQJkz7PJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_word2vec['exchange']"
      ],
      "metadata": {
        "id": "qxfQgTpkLjW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_word2vec.wv.vectors"
      ],
      "metadata": {
        "id": "v5kd1CE9LW3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wikiw2v = gensim.downloader.load('glove-wiki-gigaword-100')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LanKU5cc6hHQ",
        "outputId": "ec7311da-d5b8-41c1-d921-f63f4228158b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 128.1/128.1MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import KeyedVectors"
      ],
      "metadata": {
        "id": "Krq-fzI67aA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wikiw2v.wv.vocab"
      ],
      "metadata": {
        "id": "PMFVqduY6zKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wikiw2v['the']"
      ],
      "metadata": {
        "id": "Mq1hZAyc7-3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wikiw2v.wv.vectors"
      ],
      "metadata": {
        "id": "flM7blvF79Lu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZExHPYxHGMI3"
      },
      "outputs": [],
      "source": [
        "train_df, eval_df = train_test_split(df, train_size = 0.9,test_size = 0.1, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O8d4VlAEDkIa"
      },
      "outputs": [],
      "source": [
        "class RegulationDataset(Dataset):\n",
        "    def __init__(self, dataframe):\n",
        "        self.dataframe = dataframe\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "      \n",
        "    def __getitem__(self, index):        \n",
        "        data_row = self.dataframe.iloc[index]\n",
        "\n",
        "        features = data_row['pretrained']\n",
        "        labels = data_row[label_cols]\n",
        "\n",
        "        return torch.FloatTensor(features), torch.FloatTensor(labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jhyGmhHYmjVK"
      },
      "outputs": [],
      "source": [
        "class RegulationTestDataset(Dataset):\n",
        "    def __init__(self, dataframe):\n",
        "        self.dataframe = dataframe\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "      \n",
        "    def __getitem__(self, index):        \n",
        "        data_row = self.dataframe.iloc[index]\n",
        "\n",
        "        features = data_row['pretrained']\n",
        "\n",
        "        return torch.FloatTensor(features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0D5VVl3ZFezw"
      },
      "outputs": [],
      "source": [
        "train_dataset = RegulationDataset(train_df)\n",
        "eval_dataset = RegulationDataset(eval_df)\n",
        "test_dataset = RegulationTestDataset(test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9jnMONLLkZvF"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tZ_ts5-l9rbV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import keras  # only for loading the dataset and preprocessing\n",
        "import keras_preprocessing\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from gensim.models import word2vec\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "qWJ3YFOI9rYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, eval_df = train_test_split(df, train_size = 0.8,test_size = 0.2, random_state=42)"
      ],
      "metadata": {
        "id": "uDNs0EJu-jaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "item"
      ],
      "metadata": {
        "id": "iN5rmztnNAGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lens = []\n",
        "for item in df['pretrained']:\n",
        "    lens.append(len(item))"
      ],
      "metadata": {
        "id": "SCLphrRyL8pv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.Series(lens).quartiles(0.9)"
      ],
      "metadata": {
        "id": "qSK6M31rNn8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DOC_LEN = 384\n",
        "train_x = keras.utils.pad_sequences(train_df['pretrained'],\n",
        "                                    value=0,\n",
        "                                    padding='post',\n",
        "                                    maxlen=DOC_LEN)\n",
        "\n",
        "eval_x = keras.utils.pad_sequences(eval_df['pretrained'],\n",
        "                                    value=0,\n",
        "                                    padding='post',\n",
        "                                    maxlen=DOC_LEN)\n",
        "\n",
        "test_x = keras.utils.pad_sequences(test_df['pretrained'],\n",
        "                                    value=0,\n",
        "                                    padding='post',\n",
        "                                    maxlen=DOC_LEN)\n",
        "\n",
        "print(train_x.shape)\n",
        "print(eval_x.shape)\n",
        "print(test_x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "marXtvYR9rXH",
        "outputId": "129e2859-90e1-4039-b782-90701b267393"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7887, 384)\n",
            "(1972, 384)\n",
            "(4993, 384)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-oR8jRNy6-f_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_x[0])"
      ],
      "metadata": {
        "id": "NfZJa4Kt9yO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RegulationDataset(Dataset):\n",
        "    def __init__(self, features, dataframe):\n",
        "        self.dataframe = dataframe\n",
        "        self.features = torch.IntTensor(features)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "      \n",
        "    def __getitem__(self, index):        \n",
        "        data_row = self.dataframe.iloc[index]\n",
        "\n",
        "        labels = data_row[label_cols]\n",
        "\n",
        "        return self.features[index], torch.FloatTensor(labels)"
      ],
      "metadata": {
        "id": "82Y9kafw9yI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RegulationTestDataset(Dataset):\n",
        "    def __init__(self, features):\n",
        "        self.features = torch.IntTensor(features)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "      \n",
        "    def __getitem__(self, index):        \n",
        "        return self.features[index]"
      ],
      "metadata": {
        "id": "TjqYlFXa-dad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# datasets\n",
        "train_dataset = RegulationDataset(train_x, train_df)\n",
        "\n",
        "eval_dataset = RegulationDataset(eval_x, eval_df)\n",
        "\n",
        "test_dataset = RegulationTestDataset(test_x)"
      ],
      "metadata": {
        "id": "sC6Ecosv97B9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextCNN(nn.Module):\n",
        "    def __init__(self, weights, embedding_dim, out_channels, dropout_ratio):\n",
        "        super(TextCNN, self).__init__()\n",
        "        self.weights = weights\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.dropout_ratio = dropout_ratio\n",
        "        \n",
        "        # embedding\n",
        "        self.embedding = nn.Embedding.from_pretrained(self.weights)  # (-1, DOC_LEN, embedding_dim), num_embedding: embedding dict size, embedding_dim: length of embedding vector\n",
        "        \n",
        "        # 1D CNN\n",
        "        # unigram\n",
        "        self.unigram = nn.Sequential(# input (-1, embedding_dim, DOC_LEN)\n",
        "        nn.Conv1d(in_channels=embedding_dim, out_channels=out_channels, kernel_size=2),  # (-1, 64, DOC_LEN)\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool1d(kernel_size=DOC_LEN - 2 + 1),  # (-1, 64, 1)\n",
        "        nn.Flatten()  # (-1, 64 * 1)\n",
        "        )\n",
        "        # bigram\n",
        "        self.bigram = nn.Sequential(# input (-1, embedding_dim, DOC_LEN)\n",
        "        nn.Conv1d(in_channels=embedding_dim, out_channels=out_channels, kernel_size=3),  # (-1, 64, DOC_LEN-2+1) ??? why DOC_LEN - 2 + 1\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool1d(kernel_size=DOC_LEN - 3 + 1),  # (-1, 64, 1)\n",
        "        nn.Flatten()  # (-1, 64 * 1)\n",
        "        )\n",
        "        # trigram\n",
        "        self.trigram = nn.Sequential(# input (-1, embedding_dim, DOC_LEN)\n",
        "        nn.Conv1d(in_channels=embedding_dim, out_channels=out_channels, kernel_size=4),  # (-1, 64, DOC_LEN-3+1)\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool1d(kernel_size=DOC_LEN - 4 + 1),  # (-1, 16, 7)\n",
        "        nn.Flatten()  # (-1, 64 * 1)\n",
        "        )\n",
        "        # simple classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(dropout_ratio),\n",
        "            nn.Linear(in_features=out_channels*3, out_features=50)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        # get embedding\n",
        "        x = self.embedding(x)\n",
        "        # make sure we are convolving on each word\n",
        "        x = torch.transpose(x, dim0=1, dim1=2)  # (-1, DOC_LEN, embedding_dim): embedding on 1(DOC_LEN) & 2(embedding_dim) dims\n",
        "        # 1d cnn output\n",
        "        uni_gram_output = self.unigram(x)\n",
        "        bi_gram_output = self.bigram(x)\n",
        "        tri_gram_output = self.trigram(x)\n",
        "\n",
        "        # concatenate\n",
        "        x = torch.cat((uni_gram_output, bi_gram_output, tri_gram_output), dim=1)\n",
        "        # classifier\n",
        "        x = self.classifier(x)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "I57T19nZAgPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights = torch.FloatTensor(my_word2vec.wv.vectors)"
      ],
      "metadata": {
        "id": "JExWLFpc6bD1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=TextCNN(weights,300,1024,0.3)"
      ],
      "metadata": {
        "id": "3MPpL53PAjEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torchinfo"
      ],
      "metadata": {
        "id": "2W1OmiEMk7iy",
        "outputId": "36c397db-75e7-4c3e-a3b7-e06ebe70f929",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.7.1-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchinfo import summary"
      ],
      "metadata": {
        "id": "qM9pri8tk60V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(TextCNN(weights,300,1024,0.3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88a7rm1KkvkD",
        "outputId": "5e104a6a-5cbc-4b53-8936-43d6930b2d3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "=================================================================\n",
              "Layer (type:depth-idx)                   Param #\n",
              "=================================================================\n",
              "TextCNN                                  --\n",
              "├─Embedding: 1-1                         (10,341,900)\n",
              "├─Sequential: 1-2                        --\n",
              "│    └─Conv1d: 2-1                       615,424\n",
              "│    └─ReLU: 2-2                         --\n",
              "│    └─MaxPool1d: 2-3                    --\n",
              "│    └─Flatten: 2-4                      --\n",
              "├─Sequential: 1-3                        --\n",
              "│    └─Conv1d: 2-5                       922,624\n",
              "│    └─ReLU: 2-6                         --\n",
              "│    └─MaxPool1d: 2-7                    --\n",
              "│    └─Flatten: 2-8                      --\n",
              "├─Sequential: 1-4                        --\n",
              "│    └─Conv1d: 2-9                       1,229,824\n",
              "│    └─ReLU: 2-10                        --\n",
              "│    └─MaxPool1d: 2-11                   --\n",
              "│    └─Flatten: 2-12                     --\n",
              "├─Sequential: 1-5                        --\n",
              "│    └─Dropout: 2-13                     --\n",
              "│    └─Linear: 2-14                      153,650\n",
              "=================================================================\n",
              "Total params: 13,263,422\n",
              "Trainable params: 2,921,522\n",
              "Non-trainable params: 10,341,900\n",
              "================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_dataset, test_dataset, device, lr=0.0001, epochs=20, batch_size=32):\n",
        "    # construct dataloader\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    # move model to device\n",
        "    model = model.to(device)\n",
        "\n",
        "    # history\n",
        "    history = {'train_loss': [],\n",
        "               'train_acc': [],\n",
        "               'test_loss': [],\n",
        "               'test_acc': []}\n",
        "\n",
        "    # setup loss function and optimizer\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=0.0005)\n",
        "\n",
        "    # training loop\n",
        "    print('Training Start')\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        train_acc = 0\n",
        "        test_loss = 0\n",
        "        test_acc = 0\n",
        "        for x, y in train_loader:\n",
        "            # move data to device\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "            # forward\n",
        "            outputs = model(x)\n",
        "            pred = torch.round(torch.sigmoid(outputs))\n",
        "            cur_train_loss = criterion(outputs, y)\n",
        "            cur_train_acc = (pred == y).float().mean().item() \n",
        "            # backward\n",
        "            cur_train_loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            # loss and acc\n",
        "            train_loss += cur_train_loss\n",
        "            train_acc += cur_train_acc\n",
        "\n",
        "        # test start\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for x, y in test_loader:\n",
        "                # move\n",
        "                x = x.to(device)\n",
        "                y = y.to(device)\n",
        "                # predict\n",
        "                outputs = model(x)\n",
        "                pred = torch.round(torch.sigmoid(outputs))\n",
        "                cur_test_loss = criterion(outputs, y)\n",
        "                cur_test_acc = (pred == y).float().mean().item() \n",
        "                # loss and acc\n",
        "                test_loss += cur_test_loss\n",
        "                test_acc += cur_test_acc\n",
        "\n",
        "        # epoch output\n",
        "        train_loss = (train_loss/len(train_loader)).item()\n",
        "        train_acc = train_acc/len(train_loader)\n",
        "        val_loss = (test_loss/len(test_loader)).item()\n",
        "        val_acc = test_acc/len(test_loader)\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['train_acc'].append(train_acc)\n",
        "        history['test_loss'].append(val_loss)\n",
        "        history['test_acc'].append(val_acc)\n",
        "        print(f\"Epoch:{epoch + 1} / {epochs}, train loss:{train_loss:.4f} train_acc:{train_acc:.4f}, valid loss:{val_loss:.4f} valid acc:{val_acc:.5f}\")\n",
        "    \n",
        "    return history"
      ],
      "metadata": {
        "id": "ZsEnK4FDA2ZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "OPfkqA2tA9Fp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = train_model(model=model,\n",
        "                      train_dataset=train_dataset,\n",
        "                      test_dataset=eval_dataset,\n",
        "                      device=device,\n",
        "                      lr=0.005,\n",
        "                      epochs=5,\n",
        "                      batch_size=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9hKzJEEXbkB",
        "outputId": "ec31ec09-8693-449b-9387-3c78549cbc22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Start\n",
            "Epoch:1 / 5, train loss:0.2500 train_acc:0.9210, valid loss:0.1589 valid acc:0.94248\n",
            "Epoch:2 / 5, train loss:0.1362 train_acc:0.9517, valid loss:0.1191 valid acc:0.95538\n",
            "Epoch:3 / 5, train loss:0.1153 train_acc:0.9586, valid loss:0.1133 valid acc:0.95979\n",
            "Epoch:4 / 5, train loss:0.1061 train_acc:0.9618, valid loss:0.1055 valid acc:0.96256\n",
            "Epoch:5 / 5, train loss:0.1014 train_acc:0.9635, valid loss:0.1014 valid acc:0.96360\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = train_model(model=model,\n",
        "                      train_dataset=train_dataset,\n",
        "                      test_dataset=eval_dataset,\n",
        "                      device=device,\n",
        "                      lr=0.0005,\n",
        "                      epochs=2,\n",
        "                      batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yC1cpCYQd5Dg",
        "outputId": "d4ae2620-a1aa-4d68-f044-6d6d5bc7a14a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Start\n",
            "Epoch:1 / 2, train loss:0.0768 train_acc:0.9724, valid loss:0.0872 valid acc:0.96923\n",
            "Epoch:2 / 2, train loss:0.0679 train_acc:0.9758, valid loss:0.0847 valid acc:0.96947\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = train_model(model=model,\n",
        "                      train_dataset=train_dataset,\n",
        "                      test_dataset=eval_dataset,\n",
        "                      device=device,\n",
        "                      lr=0.00005,\n",
        "                      epochs=8,\n",
        "                      batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "qUhfDMoYeFPU",
        "outputId": "36830be4-5589-43c3-e17d-6076c27c77e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Start\n",
            "Epoch:1 / 8, train loss:0.0601 train_acc:0.9789, valid loss:0.0837 valid acc:0.97010\n",
            "Epoch:2 / 8, train loss:0.0593 train_acc:0.9795, valid loss:0.0832 valid acc:0.97012\n",
            "Epoch:3 / 8, train loss:0.0593 train_acc:0.9794, valid loss:0.0830 valid acc:0.96994\n",
            "Epoch:4 / 8, train loss:0.0581 train_acc:0.9797, valid loss:0.0826 valid acc:0.97039\n",
            "Epoch:5 / 8, train loss:0.0577 train_acc:0.9801, valid loss:0.0824 valid acc:0.97054\n",
            "Epoch:6 / 8, train loss:0.0571 train_acc:0.9803, valid loss:0.0825 valid acc:0.97049\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-313-f7a4f2699912>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m                       \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.00005\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                       \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                       batch_size=32)\n\u001b[0m",
            "\u001b[0;32m<ipython-input-306-448d7541a1e8>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_dataset, test_dataset, device, lr, epochs, batch_size)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0;31m# move data to device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    679\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    722\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-975f01851d48>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mdata_row\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_row\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    964\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 966\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    967\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_with\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0;31m# handle the dup indexing case GH#4246\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1006\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_values_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1151\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot index with multidimensional key\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1153\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m             \u001b[0;31m# nested tuple slicing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m         \u001b[0;31m# A collection of keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1093\u001b[0;31m         \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1094\u001b[0m         return self.obj._reindex_with_indexers(\n\u001b[1;32m   1095\u001b[0m             \u001b[0;34m{\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1292\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1293\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1294\u001b[0;31m             \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray_tuplesafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultiIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/common.py\u001b[0m in \u001b[0;36masarray_tuplesafe\u001b[0;34m(values, dtype)\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__array__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m         \u001b[0;31m# error: Incompatible return value type (got \"Union[ExtensionArray, ndarray]\",\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0;31m# expected \"ndarray\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/dtypes/generic.py\u001b[0m in \u001b[0;36m_check\u001b[0;34m(cls, inst)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minst\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_typ\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcomp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mdct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"__instancecheck__\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_check\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__subclasscheck__\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_check\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = train_model(model=model,\n",
        "                      train_dataset=train_dataset,\n",
        "                      test_dataset=eval_dataset,\n",
        "                      device=device,\n",
        "                      lr=0.00001,\n",
        "                      epochs=2,\n",
        "                      batch_size=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ziMNGXeuXbbN",
        "outputId": "e02f8785-1ca4-42b0-eac5-d3854d1d293a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Start\n",
            "Epoch:1 / 2, train loss:0.0561 train_acc:0.9806, valid loss:0.0821 valid acc:0.97057\n",
            "Epoch:2 / 2, train loss:0.0560 train_acc:0.9807, valid loss:0.0820 valid acc:0.97053\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = train_model(model=model,\n",
        "                      train_dataset=train_dataset,\n",
        "                      test_dataset=eval_dataset,\n",
        "                      device=device,\n",
        "                      lr=0.000008,\n",
        "                      epochs=2,\n",
        "                      batch_size=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m97myXzGyWhI",
        "outputId": "779db052-64ac-4a2c-c8cb-1ada09c16249"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Start\n",
            "Epoch:1 / 2, train loss:0.0556 train_acc:0.9809, valid loss:0.0820 valid acc:0.97055\n",
            "Epoch:2 / 2, train loss:0.0562 train_acc:0.9806, valid loss:0.0818 valid acc:0.97067\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = train_model(model=model,\n",
        "                      train_dataset=train_dataset,\n",
        "                      test_dataset=eval_dataset,\n",
        "                      device=device,\n",
        "                      lr=0.00002,\n",
        "                      epochs=5,\n",
        "                      batch_size=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2ZA3RPlyqFX",
        "outputId": "28f12719-fa7a-46d2-d39d-81b60fa903a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Start\n",
            "Epoch:1 / 5, train loss:0.0555 train_acc:0.9811, valid loss:0.0820 valid acc:0.97053\n",
            "Epoch:2 / 5, train loss:0.0556 train_acc:0.9810, valid loss:0.0818 valid acc:0.97071\n",
            "Epoch:3 / 5, train loss:0.0553 train_acc:0.9811, valid loss:0.0818 valid acc:0.97065\n",
            "Epoch:4 / 5, train loss:0.0553 train_acc:0.9809, valid loss:0.0818 valid acc:0.97072\n",
            "Epoch:5 / 5, train loss:0.0547 train_acc:0.9814, valid loss:0.0816 valid acc:0.97077\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = train_model(model=model,\n",
        "                      train_dataset=train_dataset,\n",
        "                      test_dataset=eval_dataset,\n",
        "                      device=device,\n",
        "                      lr=0.00005,\n",
        "                      epochs=3,\n",
        "                      batch_size=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pb2xAtpzPBV",
        "outputId": "5fff1a74-020b-469b-b837-95413cc71cc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Start\n",
            "Epoch:1 / 3, train loss:0.0553 train_acc:0.9810, valid loss:0.0815 valid acc:0.97080\n",
            "Epoch:2 / 3, train loss:0.0551 train_acc:0.9810, valid loss:0.0819 valid acc:0.97043\n",
            "Epoch:3 / 3, train loss:0.0544 train_acc:0.9814, valid loss:0.0814 valid acc:0.97066\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = train_model(model=model,\n",
        "                      train_dataset=train_dataset,\n",
        "                      test_dataset=eval_dataset,\n",
        "                      device=device,\n",
        "                      lr=0.0001,\n",
        "                      epochs=3,\n",
        "                      batch_size=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CoFkWlM2zfP8",
        "outputId": "1db01c44-da56-462c-fb31-40a6451fec1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Start\n",
            "Epoch:1 / 3, train loss:0.0512 train_acc:0.9828, valid loss:0.0803 valid acc:0.97129\n",
            "Epoch:2 / 3, train loss:0.0495 train_acc:0.9837, valid loss:0.0799 valid acc:0.97134\n",
            "Epoch:3 / 3, train loss:0.0496 train_acc:0.9836, valid loss:0.0795 valid acc:0.97149\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = train_model(model=model,\n",
        "                      train_dataset=train_dataset,\n",
        "                      test_dataset=eval_dataset,\n",
        "                      device=device,\n",
        "                      lr=0.0001,\n",
        "                      epochs=3,\n",
        "                      batch_size=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTct0eog05gW",
        "outputId": "2c9e1d11-e54e-4dab-e3ac-d13514f09521"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Start\n",
            "Epoch:1 / 3, train loss:0.0491 train_acc:0.9839, valid loss:0.0791 valid acc:0.97156\n",
            "Epoch:2 / 3, train loss:0.0484 train_acc:0.9840, valid loss:0.0792 valid acc:0.97153\n",
            "Epoch:3 / 3, train loss:0.0475 train_acc:0.9846, valid loss:0.0791 valid acc:0.97158\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = train_model(model=model,\n",
        "                      train_dataset=train_dataset,\n",
        "                      test_dataset=eval_dataset,\n",
        "                      device=device,\n",
        "                      lr=0.0001,\n",
        "                      epochs=3,\n",
        "                      batch_size=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hArJ5Hrg1kKP",
        "outputId": "9f509312-3ff2-483a-a9b4-1f63e09419e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Start\n",
            "Epoch:1 / 3, train loss:0.0472 train_acc:0.9847, valid loss:0.0787 valid acc:0.97167\n",
            "Epoch:2 / 3, train loss:0.0461 train_acc:0.9852, valid loss:0.0786 valid acc:0.97181\n",
            "Epoch:3 / 3, train loss:0.0458 train_acc:0.9851, valid loss:0.0784 valid acc:0.97198\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = train_model(model=model,\n",
        "                      train_dataset=train_dataset,\n",
        "                      test_dataset=eval_dataset,\n",
        "                      device=device,\n",
        "                      lr=0.0001,\n",
        "                      epochs=3,\n",
        "                      batch_size=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-g-svL8m106a",
        "outputId": "cc3c8fac-8802-4c9c-b833-b18d13bb95d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Start\n",
            "Epoch:1 / 3, train loss:0.0428 train_acc:0.9864, valid loss:0.0776 valid acc:0.97195\n",
            "Epoch:2 / 3, train loss:0.0416 train_acc:0.9871, valid loss:0.0775 valid acc:0.97231\n",
            "Epoch:3 / 3, train loss:0.0411 train_acc:0.9874, valid loss:0.0776 valid acc:0.97196\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = train_model(model=model,\n",
        "                      train_dataset=train_dataset,\n",
        "                      test_dataset=eval_dataset,\n",
        "                      device=device,\n",
        "                      lr=0.0001,\n",
        "                      epochs=3,\n",
        "                      batch_size=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1neSgGCT2Rqn",
        "outputId": "08e6eeea-f884-4180-a10e-68986b7461bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Start\n",
            "Epoch:1 / 3, train loss:0.0411 train_acc:0.9873, valid loss:0.0775 valid acc:0.97239\n",
            "Epoch:2 / 3, train loss:0.0404 train_acc:0.9878, valid loss:0.0768 valid acc:0.97254\n",
            "Epoch:3 / 3, train loss:0.0396 train_acc:0.9883, valid loss:0.0769 valid acc:0.97286\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = train_model(model=model,\n",
        "                      train_dataset=train_dataset,\n",
        "                      test_dataset=eval_dataset,\n",
        "                      device=device,\n",
        "                      lr=0.0001,\n",
        "                      epochs=10,\n",
        "                      batch_size=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcAFTibA2kW1",
        "outputId": "014f0607-cfc4-4194-fe05-9413006b283e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Start\n",
            "Epoch:1 / 10, train loss:0.0395 train_acc:0.9881, valid loss:0.0766 valid acc:0.97283\n",
            "Epoch:2 / 10, train loss:0.0387 train_acc:0.9885, valid loss:0.0768 valid acc:0.97246\n",
            "Epoch:3 / 10, train loss:0.0381 train_acc:0.9889, valid loss:0.0769 valid acc:0.97248\n",
            "Epoch:4 / 10, train loss:0.0381 train_acc:0.9889, valid loss:0.0762 valid acc:0.97272\n",
            "Epoch:5 / 10, train loss:0.0377 train_acc:0.9890, valid loss:0.0764 valid acc:0.97311\n",
            "Epoch:6 / 10, train loss:0.0372 train_acc:0.9892, valid loss:0.0768 valid acc:0.97276\n",
            "Epoch:7 / 10, train loss:0.0364 train_acc:0.9896, valid loss:0.0761 valid acc:0.97271\n",
            "Epoch:8 / 10, train loss:0.0364 train_acc:0.9896, valid loss:0.0767 valid acc:0.97267\n",
            "Epoch:9 / 10, train loss:0.0361 train_acc:0.9897, valid loss:0.0760 valid acc:0.97295\n",
            "Epoch:10 / 10, train loss:0.0358 train_acc:0.9900, valid loss:0.0759 valid acc:0.97319\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = train_model(model=model,\n",
        "                      train_dataset=train_dataset,\n",
        "                      test_dataset=eval_dataset,\n",
        "                      device=device,\n",
        "                      lr=0.0001,\n",
        "                      epochs=10,\n",
        "                      batch_size=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5dDLhzE2kSJ",
        "outputId": "6a0c6270-d961-416c-f252-96d87911e3e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Start\n",
            "Epoch:1 / 10, train loss:0.0357 train_acc:0.9900, valid loss:0.0760 valid acc:0.97309\n",
            "Epoch:2 / 10, train loss:0.0348 train_acc:0.9905, valid loss:0.0763 valid acc:0.97266\n",
            "Epoch:3 / 10, train loss:0.0347 train_acc:0.9905, valid loss:0.0759 valid acc:0.97287\n",
            "Epoch:4 / 10, train loss:0.0346 train_acc:0.9904, valid loss:0.0757 valid acc:0.97285\n",
            "Epoch:5 / 10, train loss:0.0343 train_acc:0.9906, valid loss:0.0759 valid acc:0.97288\n",
            "Epoch:6 / 10, train loss:0.0338 train_acc:0.9910, valid loss:0.0754 valid acc:0.97320\n",
            "Epoch:7 / 10, train loss:0.0334 train_acc:0.9910, valid loss:0.0753 valid acc:0.97318\n",
            "Epoch:8 / 10, train loss:0.0332 train_acc:0.9912, valid loss:0.0754 valid acc:0.97325\n",
            "Epoch:9 / 10, train loss:0.0328 train_acc:0.9913, valid loss:0.0753 valid acc:0.97326\n",
            "Epoch:10 / 10, train loss:0.0327 train_acc:0.9915, valid loss:0.0753 valid acc:0.97324\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = train_model(model=model,\n",
        "                      train_dataset=train_dataset,\n",
        "                      test_dataset=eval_dataset,\n",
        "                      device=device,\n",
        "                      lr=0.0001,\n",
        "                      epochs=10,\n",
        "                      batch_size=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCsiQIGT3Ysq",
        "outputId": "d541e71f-780d-48d0-de80-7621a9ca5751"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Start\n",
            "Epoch:1 / 10, train loss:0.0330 train_acc:0.9913, valid loss:0.0754 valid acc:0.97311\n",
            "Epoch:2 / 10, train loss:0.0320 train_acc:0.9918, valid loss:0.0755 valid acc:0.97275\n",
            "Epoch:3 / 10, train loss:0.0318 train_acc:0.9920, valid loss:0.0748 valid acc:0.97312\n",
            "Epoch:4 / 10, train loss:0.0318 train_acc:0.9917, valid loss:0.0756 valid acc:0.97323\n",
            "Epoch:5 / 10, train loss:0.0314 train_acc:0.9919, valid loss:0.0753 valid acc:0.97300\n",
            "Epoch:6 / 10, train loss:0.0312 train_acc:0.9920, valid loss:0.0752 valid acc:0.97315\n",
            "Epoch:7 / 10, train loss:0.0313 train_acc:0.9922, valid loss:0.0747 valid acc:0.97362\n",
            "Epoch:8 / 10, train loss:0.0308 train_acc:0.9923, valid loss:0.0751 valid acc:0.97317\n",
            "Epoch:9 / 10, train loss:0.0303 train_acc:0.9926, valid loss:0.0749 valid acc:0.97350\n",
            "Epoch:10 / 10, train loss:0.0304 train_acc:0.9924, valid loss:0.0753 valid acc:0.97341\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = train_model(model=model,\n",
        "                      train_dataset=train_dataset,\n",
        "                      test_dataset=eval_dataset,\n",
        "                      device=device,\n",
        "                      lr=0.0001,\n",
        "                      epochs=20,\n",
        "                      batch_size=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOFuNGQZ3YrI",
        "outputId": "93a0a594-513b-4441-fae7-84ebf788d936"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Start\n",
            "Epoch:1 / 20, train loss:0.0305 train_acc:0.9924, valid loss:0.0755 valid acc:0.97306\n",
            "Epoch:2 / 20, train loss:0.0305 train_acc:0.9925, valid loss:0.0750 valid acc:0.97323\n",
            "Epoch:3 / 20, train loss:0.0298 train_acc:0.9927, valid loss:0.0755 valid acc:0.97334\n",
            "Epoch:4 / 20, train loss:0.0297 train_acc:0.9928, valid loss:0.0761 valid acc:0.97288\n",
            "Epoch:5 / 20, train loss:0.0297 train_acc:0.9929, valid loss:0.0748 valid acc:0.97348\n",
            "Epoch:6 / 20, train loss:0.0295 train_acc:0.9929, valid loss:0.0751 valid acc:0.97334\n",
            "Epoch:7 / 20, train loss:0.0292 train_acc:0.9930, valid loss:0.0750 valid acc:0.97329\n",
            "Epoch:8 / 20, train loss:0.0293 train_acc:0.9931, valid loss:0.0760 valid acc:0.97296\n",
            "Epoch:9 / 20, train loss:0.0289 train_acc:0.9931, valid loss:0.0749 valid acc:0.97367\n",
            "Epoch:10 / 20, train loss:0.0290 train_acc:0.9932, valid loss:0.0758 valid acc:0.97294\n",
            "Epoch:11 / 20, train loss:0.0287 train_acc:0.9934, valid loss:0.0750 valid acc:0.97341\n",
            "Epoch:12 / 20, train loss:0.0286 train_acc:0.9933, valid loss:0.0747 valid acc:0.97336\n",
            "Epoch:13 / 20, train loss:0.0284 train_acc:0.9936, valid loss:0.0748 valid acc:0.97353\n",
            "Epoch:14 / 20, train loss:0.0283 train_acc:0.9936, valid loss:0.0750 valid acc:0.97322\n",
            "Epoch:15 / 20, train loss:0.0283 train_acc:0.9934, valid loss:0.0746 valid acc:0.97350\n",
            "Epoch:16 / 20, train loss:0.0279 train_acc:0.9935, valid loss:0.0750 valid acc:0.97344\n",
            "Epoch:17 / 20, train loss:0.0278 train_acc:0.9939, valid loss:0.0745 valid acc:0.97370\n",
            "Epoch:18 / 20, train loss:0.0276 train_acc:0.9938, valid loss:0.0749 valid acc:0.97348\n",
            "Epoch:19 / 20, train loss:0.0277 train_acc:0.9938, valid loss:0.0748 valid acc:0.97363\n",
            "Epoch:20 / 20, train loss:0.0276 train_acc:0.9940, valid loss:0.0753 valid acc:0.97331\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = torch.load('/content/drive/MyDrive/DataSolve/competition/Word2Vec+LSTM/output/regulation22.t7')\n",
        "model.load_state_dict(checkpoint['model'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PY_ExV413Ym3",
        "outputId": "ebbc9ebc-88db-4302-cd36-92e33978ff56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 364
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = train_model(model=model,\n",
        "                      train_dataset=train_dataset,\n",
        "                      test_dataset=eval_dataset,\n",
        "                      device=device,\n",
        "                      lr=0.0001,\n",
        "                      epochs=20,\n",
        "                      batch_size=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGNdookB7KXo",
        "outputId": "a0747786-5594-4e27-e1e0-c4b54254d740"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Start\n",
            "Epoch:1 / 20, train loss:0.0276 train_acc:0.9938, valid loss:0.0748 valid acc:0.97359\n",
            "Epoch:2 / 20, train loss:0.0273 train_acc:0.9940, valid loss:0.0745 valid acc:0.97355\n",
            "Epoch:3 / 20, train loss:0.0270 train_acc:0.9941, valid loss:0.0749 valid acc:0.97353\n",
            "Epoch:4 / 20, train loss:0.0272 train_acc:0.9940, valid loss:0.0750 valid acc:0.97353\n",
            "Epoch:5 / 20, train loss:0.0270 train_acc:0.9940, valid loss:0.0751 valid acc:0.97333\n",
            "Epoch:6 / 20, train loss:0.0268 train_acc:0.9943, valid loss:0.0749 valid acc:0.97344\n",
            "Epoch:7 / 20, train loss:0.0268 train_acc:0.9942, valid loss:0.0748 valid acc:0.97337\n",
            "Epoch:8 / 20, train loss:0.0265 train_acc:0.9942, valid loss:0.0748 valid acc:0.97350\n",
            "Epoch:9 / 20, train loss:0.0267 train_acc:0.9943, valid loss:0.0751 valid acc:0.97331\n",
            "Epoch:10 / 20, train loss:0.0266 train_acc:0.9942, valid loss:0.0747 valid acc:0.97354\n",
            "Epoch:11 / 20, train loss:0.0264 train_acc:0.9944, valid loss:0.0756 valid acc:0.97308\n",
            "Epoch:12 / 20, train loss:0.0261 train_acc:0.9946, valid loss:0.0750 valid acc:0.97346\n",
            "Epoch:13 / 20, train loss:0.0266 train_acc:0.9944, valid loss:0.0747 valid acc:0.97342\n",
            "Epoch:14 / 20, train loss:0.0263 train_acc:0.9944, valid loss:0.0746 valid acc:0.97362\n",
            "Epoch:15 / 20, train loss:0.0263 train_acc:0.9946, valid loss:0.0751 valid acc:0.97363\n",
            "Epoch:16 / 20, train loss:0.0260 train_acc:0.9946, valid loss:0.0754 valid acc:0.97324\n",
            "Epoch:17 / 20, train loss:0.0259 train_acc:0.9947, valid loss:0.0746 valid acc:0.97364\n",
            "Epoch:18 / 20, train loss:0.0259 train_acc:0.9946, valid loss:0.0745 valid acc:0.97374\n",
            "Epoch:19 / 20, train loss:0.0256 train_acc:0.9948, valid loss:0.0749 valid acc:0.97344\n",
            "Epoch:20 / 20, train loss:0.0255 train_acc:0.9948, valid loss:0.0749 valid acc:0.97353\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = train_model(model=model,\n",
        "                      train_dataset=train_dataset,\n",
        "                      test_dataset=eval_dataset,\n",
        "                      device=device,\n",
        "                      lr=0.00015,\n",
        "                      epochs=20,\n",
        "                      batch_size=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahisDErs7KUS",
        "outputId": "b9c6bd1a-b30e-4bd6-f6f1-7640a2e8bcdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Start\n",
            "Epoch:1 / 20, train loss:0.0268 train_acc:0.9942, valid loss:0.0750 valid acc:0.97323\n",
            "Epoch:2 / 20, train loss:0.0264 train_acc:0.9943, valid loss:0.0747 valid acc:0.97334\n",
            "Epoch:3 / 20, train loss:0.0261 train_acc:0.9944, valid loss:0.0759 valid acc:0.97306\n",
            "Epoch:4 / 20, train loss:0.0261 train_acc:0.9944, valid loss:0.0750 valid acc:0.97324\n",
            "Epoch:5 / 20, train loss:0.0261 train_acc:0.9947, valid loss:0.0747 valid acc:0.97364\n",
            "Epoch:6 / 20, train loss:0.0259 train_acc:0.9947, valid loss:0.0749 valid acc:0.97346\n",
            "Epoch:7 / 20, train loss:0.0257 train_acc:0.9948, valid loss:0.0762 valid acc:0.97282\n",
            "Epoch:8 / 20, train loss:0.0257 train_acc:0.9947, valid loss:0.0749 valid acc:0.97344\n",
            "Epoch:9 / 20, train loss:0.0255 train_acc:0.9947, valid loss:0.0748 valid acc:0.97355\n",
            "Epoch:10 / 20, train loss:0.0254 train_acc:0.9948, valid loss:0.0743 valid acc:0.97366\n",
            "Epoch:11 / 20, train loss:0.0257 train_acc:0.9946, valid loss:0.0750 valid acc:0.97332\n",
            "Epoch:12 / 20, train loss:0.0255 train_acc:0.9946, valid loss:0.0749 valid acc:0.97322\n",
            "Epoch:13 / 20, train loss:0.0253 train_acc:0.9948, valid loss:0.0746 valid acc:0.97335\n",
            "Epoch:14 / 20, train loss:0.0252 train_acc:0.9951, valid loss:0.0750 valid acc:0.97336\n",
            "Epoch:15 / 20, train loss:0.0251 train_acc:0.9950, valid loss:0.0741 valid acc:0.97361\n",
            "Epoch:16 / 20, train loss:0.0250 train_acc:0.9950, valid loss:0.0754 valid acc:0.97339\n",
            "Epoch:17 / 20, train loss:0.0250 train_acc:0.9950, valid loss:0.0750 valid acc:0.97319\n",
            "Epoch:18 / 20, train loss:0.0250 train_acc:0.9950, valid loss:0.0741 valid acc:0.97365\n",
            "Epoch:19 / 20, train loss:0.0247 train_acc:0.9952, valid loss:0.0754 valid acc:0.97335\n",
            "Epoch:20 / 20, train loss:0.0246 train_acc:0.9953, valid loss:0.0747 valid acc:0.97327\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = train_model(model=model,\n",
        "                      train_dataset=train_dataset,\n",
        "                      test_dataset=eval_dataset,\n",
        "                      device=device,\n",
        "                      lr=0.0001,\n",
        "                      epochs=5,\n",
        "                      batch_size=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ny_lPVrn9tCY",
        "outputId": "ff0192c9-00c8-4eb5-edac-4f4e6af736d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Start\n",
            "Epoch:1 / 5, train loss:0.0241 train_acc:0.9954, valid loss:0.0752 valid acc:0.97353\n",
            "Epoch:2 / 5, train loss:0.0240 train_acc:0.9956, valid loss:0.0749 valid acc:0.97339\n",
            "Epoch:3 / 5, train loss:0.0237 train_acc:0.9956, valid loss:0.0751 valid acc:0.97328\n",
            "Epoch:4 / 5, train loss:0.0237 train_acc:0.9957, valid loss:0.0743 valid acc:0.97336\n",
            "Epoch:5 / 5, train loss:0.0237 train_acc:0.9956, valid loss:0.0752 valid acc:0.97346\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = train_model(model=model,\n",
        "                      train_dataset=train_dataset,\n",
        "                      test_dataset=eval_dataset,\n",
        "                      device=device,\n",
        "                      lr=0.00005,\n",
        "                      epochs=4,\n",
        "                      batch_size=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhNTS0f9-Ahc",
        "outputId": "6db35cd5-1a20-46c3-d0bb-2621fb53eb29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Start\n",
            "Epoch:1 / 4, train loss:0.0232 train_acc:0.9960, valid loss:0.0747 valid acc:0.97344\n",
            "Epoch:2 / 4, train loss:0.0227 train_acc:0.9962, valid loss:0.0746 valid acc:0.97365\n",
            "Epoch:3 / 4, train loss:0.0229 train_acc:0.9962, valid loss:0.0751 valid acc:0.97334\n",
            "Epoch:4 / 4, train loss:0.0227 train_acc:0.9961, valid loss:0.0745 valid acc:0.97364\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = train_model(model=model,\n",
        "                      train_dataset=train_dataset,\n",
        "                      test_dataset=eval_dataset,\n",
        "                      device=device,\n",
        "                      lr=0.00005,\n",
        "                      epochs=10,\n",
        "                      batch_size=64)"
      ],
      "metadata": {
        "id": "BV98lA0o-q8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = train_model(model=model,\n",
        "                      train_dataset=train_dataset,\n",
        "                      test_dataset=eval_dataset,\n",
        "                      device=device,\n",
        "                      lr=0.00003,\n",
        "                      epochs=4,\n",
        "                      batch_size=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXRYmwek-_2P",
        "outputId": "3166f6a5-30cf-46ac-fd3b-2b86849ac17c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Start\n",
            "Epoch:1 / 4, train loss:0.0228 train_acc:0.9962, valid loss:0.0747 valid acc:0.97338\n",
            "Epoch:2 / 4, train loss:0.0225 train_acc:0.9963, valid loss:0.0746 valid acc:0.97359\n",
            "Epoch:3 / 4, train loss:0.0228 train_acc:0.9961, valid loss:0.0751 valid acc:0.97345\n",
            "Epoch:4 / 4, train loss:0.0224 train_acc:0.9962, valid loss:0.0747 valid acc:0.97363\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = train_model(model=model,\n",
        "                      train_dataset=train_dataset,\n",
        "                      test_dataset=eval_dataset,\n",
        "                      device=device,\n",
        "                      lr=0.00001,\n",
        "                      epochs=10,\n",
        "                      batch_size=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgzTynFB_MQ8",
        "outputId": "8404912d-af16-4312-c6eb-4246addcf2c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Start\n",
            "Epoch:1 / 10, train loss:0.0223 train_acc:0.9963, valid loss:0.0747 valid acc:0.97343\n",
            "Epoch:2 / 10, train loss:0.0222 train_acc:0.9965, valid loss:0.0748 valid acc:0.97341\n",
            "Epoch:3 / 10, train loss:0.0223 train_acc:0.9964, valid loss:0.0748 valid acc:0.97340\n",
            "Epoch:4 / 10, train loss:0.0223 train_acc:0.9964, valid loss:0.0746 valid acc:0.97346\n",
            "Epoch:5 / 10, train loss:0.0222 train_acc:0.9964, valid loss:0.0748 valid acc:0.97338\n",
            "Epoch:6 / 10, train loss:0.0220 train_acc:0.9965, valid loss:0.0749 valid acc:0.97342\n",
            "Epoch:7 / 10, train loss:0.0222 train_acc:0.9964, valid loss:0.0747 valid acc:0.97361\n",
            "Epoch:8 / 10, train loss:0.0220 train_acc:0.9966, valid loss:0.0748 valid acc:0.97350\n",
            "Epoch:9 / 10, train loss:0.0221 train_acc:0.9966, valid loss:0.0745 valid acc:0.97365\n",
            "Epoch:10 / 10, train loss:0.0223 train_acc:0.9963, valid loss:0.0746 valid acc:0.97353\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = torch.load('/content/drive/MyDrive/DataSolve/competition/Word2Vec+LSTM/output/regulation23.t7')\n",
        "model.load_state_dict(checkpoint['model'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ol9CCrpQBXyx",
        "outputId": "d2d991dc-a898-4abf-cd0c-e61422b7ad44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 383
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = train_model(model=model,\n",
        "                      train_dataset=train_dataset,\n",
        "                      test_dataset=eval_dataset,\n",
        "                      device=device,\n",
        "                      lr=0.00001,\n",
        "                      epochs=10,\n",
        "                      batch_size=256)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKyzDzZVBZSc",
        "outputId": "d29be80c-612b-4aa2-db62-3496b5edec7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Start\n",
            "Epoch:1 / 10, train loss:0.0221 train_acc:0.9966, valid loss:0.0746 valid acc:0.97349\n",
            "Epoch:2 / 10, train loss:0.0222 train_acc:0.9966, valid loss:0.0749 valid acc:0.97340\n",
            "Epoch:3 / 10, train loss:0.0220 train_acc:0.9966, valid loss:0.0749 valid acc:0.97348\n",
            "Epoch:4 / 10, train loss:0.0221 train_acc:0.9966, valid loss:0.0752 valid acc:0.97332\n",
            "Epoch:5 / 10, train loss:0.0221 train_acc:0.9965, valid loss:0.0748 valid acc:0.97341\n",
            "Epoch:6 / 10, train loss:0.0221 train_acc:0.9965, valid loss:0.0749 valid acc:0.97336\n",
            "Epoch:7 / 10, train loss:0.0221 train_acc:0.9965, valid loss:0.0749 valid acc:0.97334\n",
            "Epoch:8 / 10, train loss:0.0221 train_acc:0.9965, valid loss:0.0747 valid acc:0.97340\n",
            "Epoch:9 / 10, train loss:0.0220 train_acc:0.9966, valid loss:0.0749 valid acc:0.97342\n",
            "Epoch:10 / 10, train loss:0.0218 train_acc:0.9966, valid loss:0.0746 valid acc:0.97348\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = train_model(model=model,\n",
        "                      train_dataset=train_dataset,\n",
        "                      test_dataset=eval_dataset,\n",
        "                      device=device,\n",
        "                      lr=0.00001,\n",
        "                      epochs=10,\n",
        "                      batch_size=256)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zB6KDt1QCBTX",
        "outputId": "ef6407ab-5305-4da5-bc32-0c0324224230"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Start\n",
            "Epoch:1 / 10, train loss:0.0223 train_acc:0.9966, valid loss:0.0745 valid acc:0.97358\n",
            "Epoch:2 / 10, train loss:0.0224 train_acc:0.9967, valid loss:0.0748 valid acc:0.97333\n",
            "Epoch:3 / 10, train loss:0.0233 train_acc:0.9964, valid loss:0.0748 valid acc:0.97350\n",
            "Epoch:4 / 10, train loss:0.0235 train_acc:0.9963, valid loss:0.0754 valid acc:0.97327\n",
            "Epoch:5 / 10, train loss:0.0238 train_acc:0.9962, valid loss:0.0753 valid acc:0.97336\n",
            "Epoch:6 / 10, train loss:0.0241 train_acc:0.9962, valid loss:0.0751 valid acc:0.97341\n",
            "Epoch:7 / 10, train loss:0.0246 train_acc:0.9961, valid loss:0.0752 valid acc:0.97336\n",
            "Epoch:8 / 10, train loss:0.0249 train_acc:0.9961, valid loss:0.0756 valid acc:0.97321\n",
            "Epoch:9 / 10, train loss:0.0254 train_acc:0.9961, valid loss:0.0755 valid acc:0.97328\n",
            "Epoch:10 / 10, train loss:0.0257 train_acc:0.9958, valid loss:0.0756 valid acc:0.97319\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CNQnl1KCCxLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = train_model(model=model,\n",
        "                      train_dataset=train_dataset,\n",
        "                      test_dataset=eval_dataset,\n",
        "                      device=device,\n",
        "                      lr=0.00001,\n",
        "                      epochs=5,\n",
        "                      batch_size=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPY51_wIDaWR",
        "outputId": "3e222301-ac30-48cb-9639-79d3cd0d05c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Start\n",
            "Epoch:1 / 5, train loss:0.0096 train_acc:0.9983, valid loss:0.0875 valid acc:0.97245\n",
            "Epoch:2 / 5, train loss:0.0094 train_acc:0.9984, valid loss:0.0872 valid acc:0.97259\n",
            "Epoch:3 / 5, train loss:0.0094 train_acc:0.9984, valid loss:0.0878 valid acc:0.97254\n",
            "Epoch:4 / 5, train loss:0.0094 train_acc:0.9984, valid loss:0.0874 valid acc:0.97250\n",
            "Epoch:5 / 5, train loss:0.0092 train_acc:0.9984, valid loss:0.0875 valid acc:0.97259\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "state = { \n",
        "        'model': model.state_dict()\n",
        "        }\n",
        "save_path=\"/content/drive/MyDrive/DataSolve/competition/Word2Vec+LSTM/output\"   \n",
        "torch.save(state,save_path+'/regulation24'+\".t7\"  )"
      ],
      "metadata": {
        "id": "4XXupVXvLZ7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = train_model(model=model,\n",
        "                      train_dataset=train_dataset,\n",
        "                      test_dataset=eval_dataset,\n",
        "                      device=device,\n",
        "                      lr=0.0001,\n",
        "                      epochs=40,\n",
        "                      batch_size=256)"
      ],
      "metadata": {
        "id": "MKeF0eDtKOKu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CUDA_LAUNCH_BLOCKING=1"
      ],
      "metadata": {
        "id": "Z7YKgfQPKQ4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = torch.load('/content/drive/MyDrive/DataSolve/competition/Word2Vec+LSTM/output/regulation3.t7')\n",
        "model.load_state_dict(checkpoint['model'])"
      ],
      "metadata": {
        "id": "WpdYypJcDd4h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7765c81d-953f-43ef-f646-3ae359f1cca3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_table = []\n",
        "test_loader = DataLoader(test_dataset, batch_size=1)\n",
        "model.to(device)\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for x in test_loader:\n",
        "        # move\n",
        "        x = x.to(device)\n",
        "        # predict\n",
        "        outputs = model(x)\n",
        "        pred = torch.round(torch.sigmoid(outputs))\n",
        "        pred_table.append(pred)"
      ],
      "metadata": {
        "id": "rC_qC_jxJkvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_df = []\n",
        "def to_a(t):\n",
        "    return t.cpu().detach().numpy().reshape(50)\n",
        "for t in pred_table:\n",
        "    pred_df.append(to_a(t))\n",
        "\n",
        "test_pred = pd.DataFrame(pred_df)\n",
        "test_pred.columns = label_cols\n",
        "test_pred = test_pred.astype('int')\n",
        "test_final = pd.concat([test_df,test_pred], axis=1)"
      ],
      "metadata": {
        "id": "swAdqjkfJpUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id_table = []\n",
        "for i in test_final['id']:\n",
        "    for target in label_cols:\n",
        "        id_table.append(str(i)+'_'+target)\n",
        "        \n",
        "prediction_table = []\n",
        "for col, row in test_final.iterrows():\n",
        "    for target in label_cols:\n",
        "        prediction_table.append(row[target])"
      ],
      "metadata": {
        "id": "rYsyLQpOJsx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer = pd.concat([pd.DataFrame(id_table), pd.DataFrame(prediction_table)], axis =1)\n",
        "answer.columns = ['id', 'predictions']\n",
        "answer.to_csv('answer_w2vCNNv24.csv', header=True, index=False)\n",
        "answer"
      ],
      "metadata": {
        "id": "GwJE_1TKJvxI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "e52957f4-54ae-42f9-8848-5668ac395500"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                 id  predictions\n",
              "0       4771_Accounting and Finance            1\n",
              "1                    4771_Antitrust            0\n",
              "2                      4771_Banking            0\n",
              "3                4771_Broker Dealer            0\n",
              "4          4771_Commodities Trading            0\n",
              "...                             ...          ...\n",
              "249645  57235_Securities Management            0\n",
              "249646       57235_Securities Sales            0\n",
              "249647  57235_Securities Settlement            0\n",
              "249648          57235_Trade Pricing            0\n",
              "249649       57235_Trade Settlement            0\n",
              "\n",
              "[249650 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bb098e38-7b5a-4b03-9ad0-7a29b8b2e846\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>predictions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4771_Accounting and Finance</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4771_Antitrust</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4771_Banking</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4771_Broker Dealer</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4771_Commodities Trading</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249645</th>\n",
              "      <td>57235_Securities Management</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249646</th>\n",
              "      <td>57235_Securities Sales</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249647</th>\n",
              "      <td>57235_Securities Settlement</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249648</th>\n",
              "      <td>57235_Trade Pricing</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249649</th>\n",
              "      <td>57235_Trade Settlement</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>249650 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bb098e38-7b5a-4b03-9ad0-7a29b8b2e846')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bb098e38-7b5a-4b03-9ad0-7a29b8b2e846 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bb098e38-7b5a-4b03-9ad0-7a29b8b2e846');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 391
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}